import { NextRequest, NextResponse } from 'next/server'
import { getGenAIClient, extractText } from '@/lib/genai'

// Use Jina Reader to extract web page content
async function readWebPage(url: string): Promise<string> {
  const jinaUrl = `https://r.jina.ai/${url}`
  console.log('[Brand Style] Fetching from Jina:', jinaUrl)
  
  const response = await fetch(jinaUrl, {
    method: 'GET',
    headers: {
      'Accept': 'text/plain',
    },
    cache: 'no-store',
  })
  
  console.log('[Brand Style] Jina response status:', response.status)
  
  if (!response.ok) {
    const errorText = await response.text().catch(() => '')
    console.error('[Brand Style] Jina error response:', errorText.slice(0, 500))
    
    if (response.status === 451) {
      throw new Error('è¯¥ç½‘ç«™é˜»æ­¢äº†è‡ªåŠ¨è®¿é—®ã€‚è¯·å°è¯•å…¶ä»–å“ç‰Œç½‘ç«™é“¾æ¥')
    }
    if (response.status === 403) {
      throw new Error('è®¿é—®è¢«æ‹’ç»ï¼Œè¯·å°è¯•å…¶ä»–é“¾æ¥')
    }
    if (response.status === 422) {
      throw new Error('URL æ ¼å¼æ— æ•ˆï¼Œè¯·æ£€æŸ¥é“¾æ¥')
    }
    throw new Error(`æ— æ³•è¯»å–ç½‘é¡µ (${response.status}): ${errorText.slice(0, 100)}`)
  }
  
  const text = await response.text()
  console.log('[Brand Style] Jina response length:', text.length)
  return text
}

// Image with surrounding context for LLM analysis
interface ImageWithContext {
  url: string
  context: string
  alt: string
}

// Step 1: Extract all image URLs with their surrounding context from FULL page
function extractImagesWithContext(pageContent: string): ImageWithContext[] {
  const results: ImageWithContext[] = []
  const seen = new Set<string>()
  
  const normalizeUrl = (rawUrl: string): string => {
    let url = rawUrl.replace(/\\\//g, '/')
    if (url.startsWith('//')) url = 'https:' + url
    return url
  }
  
  const shouldSkip = (url: string): boolean => {
    const lowerUrl = url.toLowerCase()
    // Skip obvious UI elements
    if (lowerUrl.includes('logo') && !lowerUrl.includes('catalog')) return true
    if (lowerUrl.includes('favicon')) return true
    if (lowerUrl.includes('icon') && !lowerUrl.includes('collection')) return true
    if (lowerUrl.includes('/flag')) return true
    if (lowerUrl.includes('payment')) return true
    if (lowerUrl.includes('badge')) return true
    if (lowerUrl.endsWith('.svg')) return true
    // Skip tiny images
    if (/[_x-](?:16|24|32|48|64)(?:x|_|\.|-|$)/i.test(url)) return true
    return false
  }
  
  const addImage = (url: string, context: string, alt: string) => {
    const normalized = normalizeUrl(url)
    if (!normalized.startsWith('http')) return
    if (shouldSkip(normalized)) return
    
    const baseUrl = normalized.split('?')[0]
    if (seen.has(baseUrl)) return
    seen.add(baseUrl)
    
    results.push({
      url: normalized,
      context: context.slice(0, 200).replace(/\s+/g, ' ').trim(),
      alt: alt.slice(0, 100)
    })
  }
  
  // Pattern 1: Markdown images ![alt](url) with context
  const mdRegex = /(.{0,150})!\[([^\]]*)\]\(((?:https?:)?\/\/[^\s\)]+)\)(.{0,150})/g
  let match
  while ((match = mdRegex.exec(pageContent)) !== null) {
    const [, before, alt, url, after] = match
    addImage(url, `${before} [IMAGE: ${alt}] ${after}`, alt)
  }
  
  // Pattern 2: Direct image URLs with context
  const imgRegex = /(.{0,100})((?:https?:)?\/\/[^\s<>"'\)]+\.(?:jpg|jpeg|png|webp|gif)(?:\?[^\s<>"']*)?)(.{0,100})/gi
  while ((match = imgRegex.exec(pageContent)) !== null) {
    const [, before, url, after] = match
    // Skip if already captured by markdown pattern
    const normalized = normalizeUrl(url)
    if (!seen.has(normalized.split('?')[0])) {
      addImage(url, `${before} [IMAGE] ${after}`, '')
    }
  }
  
  console.log('[Brand Style] Extracted', results.length, 'images with context')
  return results.slice(0, 30) // Limit to 30 images
}

// Step 2: Use LLM to analyze images with context and identify product images
async function extractProductImageUrls(pageContent: string, pageUrl: string): Promise<string[]> {
  const genAI = getGenAIClient()
  
  // Extract all images with context from FULL page (no truncation)
  const imagesWithContext = extractImagesWithContext(pageContent)
  
  if (imagesWithContext.length === 0) {
    console.log('[Brand Style] No images found in page')
    return []
  }
  
  // Format images for LLM
  const imageList = imagesWithContext.map((img, i) => 
    `[${i + 1}] URL: ${img.url}\n    Alt: ${img.alt || '(æ— )'}\n    ä¸Šä¸‹æ–‡: ${img.context}`
  ).join('\n\n')
  
  const prompt = `ä½ æ˜¯ç”µå•†ç½‘é¡µåˆ†æä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯ä»å•†å“è¯¦æƒ…é¡µï¼ˆ${pageUrl}ï¼‰æå–çš„å›¾ç‰‡åˆ—è¡¨ã€‚

æ¯å¼ å›¾ç‰‡åŒ…å«ï¼š
- URLï¼šå›¾ç‰‡åœ°å€
- Altï¼šå›¾ç‰‡æè¿°æ–‡æœ¬
- ä¸Šä¸‹æ–‡ï¼šå›¾ç‰‡åœ¨é¡µé¢ä¸­å‰åçš„æ–‡å­—

ğŸ¯ ä»»åŠ¡ï¼šæ ¹æ®ã€ä¸Šä¸‹æ–‡ã€‘å’Œã€Alt æ–‡æœ¬ã€‘åˆ¤æ–­å“ªäº›æ˜¯ä¸»å•†å“å›¾ç‰‡ã€‚

ä¸»å•†å“å›¾ç‰‡ç‰¹å¾ï¼š
- ä¸Šä¸‹æ–‡åŒ…å«å•†å“åç§°ã€ä»·æ ¼ã€å°ºç ã€é¢œè‰²é€‰æ‹©ç­‰
- Alt æ–‡æœ¬æè¿°å•†å“ï¼ˆå¦‚ "Cashmere Sweater", "äº§å“å›¾"ï¼‰
- URL åŒ…å« productã€itemã€files ç­‰å…³é”®è¯
- é€šå¸¸æ˜¯é¡µé¢ä¸­é—´çš„å¤§å›¾

æ’é™¤ï¼š
- å¯¼èˆªæ ã€é¡µå¤´ã€é¡µè„šåŒºåŸŸçš„å›¾ç‰‡
- ä¸Šä¸‹æ–‡åŒ…å« "navigation"ã€"footer"ã€"menu"ã€"ç›¸å…³å•†å“"ã€"æ¨è"
- Logoã€å›¾æ ‡ã€å›½æ——ã€æ”¯ä»˜æ–¹å¼å›¾ç‰‡

å›¾ç‰‡åˆ—è¡¨ï¼š
${imageList}

è¾“å‡º JSONï¼ˆå¿…é¡»è¿”å›è‡³å°‘ 1 ä¸ª URLï¼‰ï¼š
{
  "productImageUrls": ["url1", "url2", ...],
  "reasoning": "ç®€çŸ­è¯´æ˜åˆ¤æ–­ä¾æ®"
}`

  console.log('[Brand Style] Asking LLM to identify product images...')
  
  try {
    const result = await genAI.models.generateContent({
      model: 'gemini-2.0-flash',
      contents: [{ role: 'user', parts: [{ text: prompt }] }]
    })

    const responseText = extractText(result) || ''
    console.log('[Brand Style] LLM response:', responseText.slice(0, 500))
    
    const jsonMatch = responseText.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0])
      const urls = (parsed.productImageUrls || parsed.productImages || []) as string[]
      
      // Normalize URLs
      const normalizedUrls = urls.map(url => {
        let normalized = url.replace(/\\\//g, '/')
        if (normalized.startsWith('//')) normalized = 'https:' + normalized
        return normalized
      }).filter(url => url.startsWith('http'))
      
      if (normalizedUrls.length > 0) {
        console.log('[Brand Style] LLM identified', normalizedUrls.length, 'product images')
        console.log('[Brand Style] Reasoning:', parsed.reasoning)
        return normalizedUrls
      }
    }
  } catch (e) {
    console.error('[Brand Style] LLM error:', e)
  }
  
  // Fallback: return first few non-logo images
  console.log('[Brand Style] LLM failed, using fallback')
  return imagesWithContext.slice(0, 5).map(img => img.url)
}

// Step 2: Load images and use VLM to select best model/product images
async function analyzeImages(imageUrls: string[]): Promise<{
  images: string[]
  modelImage: string | null
  productImage: string | null
  brandSummary: string
  brandKeywords: string[]
}> {
  if (imageUrls.length === 0) {
    throw new Error('æœªæ‰¾åˆ°å•†å“å›¾ç‰‡ï¼Œè¯·å°è¯•å…¶ä»–é“¾æ¥')
  }

  // Take first 5 images max
  const imagesToAnalyze = imageUrls.slice(0, 5)
  console.log('[Brand Style] Loading', imagesToAnalyze.length, 'product images for analysis')
  
  const genAI = getGenAIClient()
  
  // Load images with browser-like headers
  const loadedImages: { url: string; part: { inlineData: { mimeType: string; data: string } } }[] = []
  
  for (let i = 0; i < imagesToAnalyze.length; i++) {
    const url = imagesToAnalyze[i]
    try {
      console.log(`[Brand Style] Loading image ${i}:`, url.slice(0, 100))
      
      const response = await fetch(url, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
          'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
          'Referer': new URL(url).origin + '/',
        },
        cache: 'no-store',
      })
      
      if (!response.ok) {
        console.log(`[Brand Style] Image ${i} fetch failed: ${response.status}`)
        continue
      }
      
      const buffer = await response.arrayBuffer()
      
      // Skip too small or too large
      if (buffer.byteLength < 1000 || buffer.byteLength > 10 * 1024 * 1024) {
        console.log(`[Brand Style] Image ${i} size invalid: ${buffer.byteLength} bytes`)
        continue
      }
      
      // Check magic bytes
      const bytes = new Uint8Array(buffer.slice(0, 4))
      const isJpeg = bytes[0] === 0xFF && bytes[1] === 0xD8
      const isPng = bytes[0] === 0x89 && bytes[1] === 0x50 && bytes[2] === 0x4E && bytes[3] === 0x47
      const isGif = bytes[0] === 0x47 && bytes[1] === 0x49 && bytes[2] === 0x46
      const isWebp = bytes[0] === 0x52 && bytes[1] === 0x49 && bytes[2] === 0x46 && bytes[3] === 0x46
      
      if (!isJpeg && !isPng && !isGif && !isWebp) {
        console.log(`[Brand Style] Image ${i} invalid format`)
        continue
      }
      
      let mimeType = 'image/jpeg'
      if (isPng) mimeType = 'image/png'
      else if (isGif) mimeType = 'image/gif'
      else if (isWebp) mimeType = 'image/webp'
      
      const base64 = Buffer.from(buffer).toString('base64')
      console.log(`[Brand Style] Image ${i} loaded: ${mimeType}, ${buffer.byteLength} bytes`)
      
      loadedImages.push({
        url,
        part: { inlineData: { mimeType, data: base64 } }
      })
    } catch (err) {
      console.log(`[Brand Style] Image ${i} error:`, (err as Error).message)
    }
  }
  
  console.log(`[Brand Style] Successfully loaded ${loadedImages.length} images`)
  
  if (loadedImages.length === 0) {
    throw new Error('æ— æ³•åŠ è½½å•†å“å›¾ç‰‡ï¼Œè¯¥ç½‘ç«™å¯èƒ½æœ‰å›¾ç‰‡é˜²ç›—é“¾ä¿æŠ¤')
  }

  // VLM analysis
  const prompt = `ä½ æ˜¯æ—¶å°šç”µå•†ä¸“å®¶ã€‚è¿™äº›æ˜¯å•†å“è¯¦æƒ…é¡µçš„ä¸»å•†å“å›¾ç‰‡ã€‚

è¯·åˆ†æå¹¶é€‰å‡ºï¼š
1. **æœ€ä½³æ¨¡ç‰¹å›¾** (modelImageIndex): æ¨¡ç‰¹ç©¿ç€/å±•ç¤ºå•†å“çš„å›¾ç‰‡ï¼Œé€‰æœ€æ¸…æ™°çš„æ­£é¢å›¾
2. **æœ€ä½³å•†å“å›¾** (productImageIndex): çº¯å•†å“å›¾ï¼ˆæ— æ¨¡ç‰¹ï¼‰ï¼Œå¦‚æœæœ‰çš„è¯
3. **å“ç‰Œé£æ ¼**: åˆ†æå“ç‰Œè§†è§‰é£æ ¼

è¾“å‡º JSONï¼š
{
  "modelImageIndex": 0-${loadedImages.length - 1} æˆ– -1,
  "productImageIndex": 0-${loadedImages.length - 1} æˆ– -1,
  "brandSummary": "å“ç‰Œé£æ ¼æè¿°ï¼ˆ50å­—å†…ï¼‰",
  "brandKeywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"]
}`

  const result = await genAI.models.generateContent({
    model: 'gemini-2.0-flash',
    contents: [{
      role: 'user',
      parts: [
        { text: prompt },
        ...loadedImages.map(img => img.part)
      ]
    }]
  })

  const responseText = extractText(result) || ''
  console.log('[Brand Style] VLM analysis response:', responseText.slice(0, 300))
  
  const jsonMatch = responseText.match(/\{[\s\S]*\}/)
  if (!jsonMatch) {
    throw new Error('VLM åˆ†æå¤±è´¥')
  }
  
  const parsed = JSON.parse(jsonMatch[0])
  const modelIdx = parsed.modelImageIndex
  const productIdx = parsed.productImageIndex
  
  const modelImage = (modelIdx >= 0 && modelIdx < loadedImages.length) 
    ? loadedImages[modelIdx].url 
    : loadedImages[0].url
    
  const productImage = (productIdx >= 0 && productIdx < loadedImages.length)
    ? loadedImages[productIdx].url
    : null
    
  console.log('[Brand Style] Selected model image:', modelIdx)
  console.log('[Brand Style] Selected product image:', productIdx)
  
  return {
    images: loadedImages.map(img => img.url),
    modelImage,
    productImage,
    brandSummary: parsed.brandSummary || '',
    brandKeywords: parsed.brandKeywords || []
  }
}

export async function POST(request: NextRequest) {
  try {
    const { url } = await request.json()
    
    if (!url) {
      return NextResponse.json({ error: 'URL is required' }, { status: 400 })
    }

    // Step 1: Read web page content with Jina
    console.log('[Brand Style] Reading product page:', url)
    const pageContent = await readWebPage(url)

    // Step 2: Use VLM to extract product image URLs from page content
    console.log('[Brand Style] Using VLM to identify product images...')
    const imageUrls = await extractProductImageUrls(pageContent, url)
    
    if (imageUrls.length === 0) {
      throw new Error('æœªèƒ½ä»é¡µé¢è¯†åˆ«å‡ºå•†å“å›¾ç‰‡ï¼Œè¯·ç¡®è®¤é“¾æ¥æ˜¯å•†å“è¯¦æƒ…é¡µ')
    }
    console.log('[Brand Style] VLM identified', imageUrls.length, 'product images')

    // Step 3: Load images and analyze with VLM
    console.log('[Brand Style] Loading and analyzing images...')
    const analysis = await analyzeImages(imageUrls)
    console.log('[Brand Style] Analysis complete')

    return NextResponse.json({
      images: analysis.images,
      modelImage: analysis.modelImage,
      productImage: analysis.productImage,
      brandSummary: analysis.brandSummary,
      brandKeywords: analysis.brandKeywords,
      rawContent: pageContent.slice(0, 2000)
    })

  } catch (error) {
    console.error('[Brand Style] Error reading product page:', error)
    return NextResponse.json(
      { error: (error as Error).message },
      { status: 500 }
    )
  }
}

